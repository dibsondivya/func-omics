---
title: "Alzheimer's disease"
subtitle: "Machine learning analysis"
author: "Emil Johansson"
date: last-modified
date-format: "dddd [the] Do [of] MMMM YYYY"
format:
  html:
    theme: lumen
    title-block-banner: true
    smooth-scroll: true
    toc: true
    toc-depth: 4
    toc-location: right
    number-sections: true
    number-depth: 4
    code-fold: true
    code-tools: true
    code-copy: true
    code-overflow: wrap
    df-print: kable
    standalone: true
    fig-align: left
    figure:
      caption: "Figure {number}: {label}"
editor_options: 
  chunk_output_type: inline
execute:
  echo: true
  message: false
  warning: false
editor: 
  markdown: 
    wrap: 72
---

# Setup

```{r}
# Libraries we need
libs <- c(
  "tidyverse", "readxl", "limma", "ggrepel", "magrittr", "kableExtra",
  "patchwork", "DT", "tidymodels", "ggbeeswarm", "gt", "skimr", "GGally",
  "visdat", "corrr", "ggsignif", "vip", "themis", "keras", "xgboost", "kknn",
  "tensorflow", "xlsx", "HDAnalyzeR", "plotly", "umap", "uwot", "ggplotify",
  "cowplot", "ggvenn", "UpSetR", "ComplexUpset"
)

# Install missing libraries
installed_libs <- libs %in% rownames(installed.packages())
if (any(installed_libs == FALSE)) {
  install.packages(libs[!installed_libs])
}

# Load libraries
invisible(lapply(libs, library, character.only = TRUE))
```

# Data

```{r}
data <- read_tsv("data/voom_normalized.tsv")
metadata <- 
```

# Random forest classification

## Prepare data

```{r}
#Continuing after Day 2 slide 20
dds <- DESeqDataSetFromMatrix(as.matrix(countTable),
design = ~ 0 + disease + individual,
colData = sampleTable)
normCounts <- vst(dds, blind = FALSE)
```

```{r}
# Prepare data
dds <- DESeqDataSetFromMatrix(as.matrix(data),
design = ~ 0 + disease + individual,
colData = sampleTable)
normCounts <- vst(dds, blind = FALSE)
```

## Define caret functions

```{r}
#Define model fitting procedure
#NB: you will also need the packages statmod and e1071 for this analysis
library(caret)
#New score function
rfSBF$score <- function(x, y){
sd(x) / mean(x)
}
#New filter function
rfSBF$filter <- function(score, x, y){
meanLog2CPM <- rowMeans(log2(cpm(countTable) + 1))
selection <- score > quantile(score, 0.9) & meanLog2CPM > 1
names(score) %in% names(score)[selection]
}
```

```{r}
#Create training set
trainingSet <- data.frame(t(assay(normCounts)))
#Train and validate decision tree (C5.0)
dtControl <- sbfControl(
functions = rfSBF,
method = "loocv",
saveDetails = TRUE,
verbose = FALSE)
dtModel <- sbf(
trainingSet,
sampleTable$disease,
sbfControl = dtControl)
#Show model
summary(dtModel$fit)
```

```{r}
#Print confusion matrix from validation
confusionMatrix(dtModel$pred$predictions$pred, sampleTable$disease)
```









